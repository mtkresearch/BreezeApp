# ğŸ”§ Runner çµ±ä¸€ä»‹é¢å®šç¾©

## ğŸ¯ ç›®æ¨™èˆ‡ç¯„åœ

æœ¬æ–‡ä»¶å®šç¾© AI Router å°æ‰€æœ‰ Runner å¯¦ä½œçµ±ä¸€çš„æ ¸å¿ƒä»‹é¢èˆ‡è¡Œç‚ºå¥‘ç´„ï¼Œç¢ºä¿èƒ½åŠ›æ¨¡çµ„èƒ½ä»¥ä¸€è‡´æ–¹å¼èª¿ç”¨å„ç¨®æ¨è«–å¼•æ“ã€‚æ‰€æœ‰ Runner å¿…é ˆéµå¾ªæ­¤ä»‹é¢è¦ç¯„ä»¥ä¿è­‰ç³»çµ±çš„ä¸€è‡´æ€§å’Œå¯æ“´å±•æ€§ã€‚

## ğŸ”§ æ ¸å¿ƒä»‹é¢å®šç¾©

### BaseRunner ä»‹é¢ (Kotlin)

```kotlin
interface BaseRunner {
    /** åˆå§‹åŒ–æ¨¡å‹èˆ‡è³‡æº */
    fun load(config: ModelConfig): Boolean

    /** åŸ·è¡Œæ¨è«–ï¼Œstream ç‚º true æ™‚å¯å›å‚³åˆ†æ®µçµæœ */
    fun run(input: InferenceRequest, stream: Boolean = false): InferenceResult

    /** å¸è¼‰è³‡æº */
    fun unload(): Unit

    /** å›å‚³æ”¯æ´çš„èƒ½åŠ›æ¸…å–®ï¼ˆé€šå¸¸ç‚ºå–®ä¸€é …ï¼‰ */
    fun getCapabilities(): List<CapabilityType>
}
```

### èƒ½åŠ›é¡å‹å®šç¾©

```kotlin
enum class CapabilityType {
    LLM,        // å¤§èªè¨€æ¨¡å‹
    VLM,        // è¦–è¦ºèªè¨€æ¨¡å‹  
    ASR,        // èªéŸ³è­˜åˆ¥
    TTS,        // èªéŸ³åˆæˆ
    GUARDIAN    // å…§å®¹å®‰å…¨æª¢æ¸¬
}
```

## ğŸ“¦ è³‡æ–™é¡å‹å®šç¾©

### æ¨è«–è«‹æ±‚æ ¼å¼

```kotlin
data class InferenceRequest(
    val sessionId: String,                    // æœƒè©±å”¯ä¸€è­˜åˆ¥ç¢¼
    val inputs: Map<String, Any>,            // è¼¸å…¥è³‡æ–™ (æ–‡å­—ã€éŸ³è¨Šã€åœ–ç‰‡ç­‰)
    val params: Map<String, Any> = emptyMap(), // æ¨è«–åƒæ•¸
    val timestamp: Long = System.currentTimeMillis()
)
```

**è¼¸å…¥è³‡æ–™ç¯„ä¾‹**ï¼š
- **LLM**: `inputs["text"] = "ä½¿ç”¨è€…å•é¡Œ"`
- **ASR**: `inputs["audio"] = FloatArray(...)`  
- **TTS**: `inputs["text"] = "è¦åˆæˆçš„æ–‡å­—"`
- **VLM**: `inputs["image"] = Bitmap, inputs["text"] = "å•é¡Œ"`

### æ¨è«–çµæœæ ¼å¼

```kotlin
data class InferenceResult(
    val outputs: Map<String, Any>,           // è¼¸å‡ºçµæœ
    val metadata: Map<String, Any> = emptyMap(), // ä¸­ç¹¼è³‡æ–™ (å¦‚ç½®ä¿¡åº¦ã€å»¶é²ç­‰)
    val error: RunnerError? = null,          // éŒ¯èª¤è³‡è¨Š
    val partial: Boolean = false             // æ˜¯å¦ç‚ºéƒ¨åˆ†çµæœ (streaming)
)
```

**è¼¸å‡ºè³‡æ–™ç¯„ä¾‹**ï¼š
- **LLM**: `outputs["text"] = "AI å›æ‡‰"`
- **ASR**: `outputs["text"] = "è­˜åˆ¥å‡ºçš„æ–‡å­—"`
- **TTS**: `outputs["audio"] = ByteArray(...)`
- **VLM**: `outputs["text"] = "åœ–ç‰‡æè¿°"`

### éŒ¯èª¤è™•ç†æ ¼å¼

```kotlin
data class RunnerError(
    val code: String,                        // éŒ¯èª¤ç¢¼ (å¦‚ E101, E201)
    val message: String,                     // éŒ¯èª¤æè¿°
    val recoverable: Boolean = false,        // æ˜¯å¦å¯é‡è©¦
    val cause: Throwable? = null            // åŸå§‹ç•°å¸¸
)
```

## ğŸ” Streaming æ¨è«–æ“´å±•

å°æ–¼æ”¯æ´ streaming çš„ Runnerï¼Œå¯å¯¦ä½œä»¥ä¸‹æ“´å±•ä»‹é¢ï¼š

```kotlin
interface StreamingRunner : BaseRunner {
    fun runStream(
        input: InferenceRequest,
        onResult: (InferenceResult) -> Unit,    // éƒ¨åˆ†çµæœå›èª¿
        onComplete: () -> Unit,                 // å®Œæˆå›èª¿
        onError: (Throwable) -> Unit           // éŒ¯èª¤å›èª¿
    )
}
```

### æˆ–ä½¿ç”¨ Kotlin Flow

```kotlin
interface FlowStreamingRunner : BaseRunner {
    fun runAsFlow(input: InferenceRequest): Flow<InferenceResult>
}
```

## ğŸ—ï¸ å¯¦ä½œç¯„ä¾‹

### SherpaASRRunner å¯¦ä½œç¤ºä¾‹

```kotlin
class SherpaASRRunner : BaseRunner {

    private var sherpaEngine: SherpaASREngine? = null

    override fun load(config: ModelConfig): Boolean {
        return try {
            sherpaEngine = SherpaASREngine().apply {
                init(config.files["model"] ?: error("Model file not specified"))
            }
            true
        } catch (e: Exception) {
            Log.e("SherpaASRRunner", "Failed to load model", e)
            false
        }
    }

    override fun run(input: InferenceRequest, stream: Boolean): InferenceResult {
        return try {
            val audioData = input.inputs["audio"] as? FloatArray
                ?: return InferenceResult(
                    outputs = emptyMap(),
                    error = RunnerError("E401", "Audio input required", false)
                )

            val result = sherpaEngine?.infer(audioData)
            InferenceResult(
                outputs = mapOf("text" to (result ?: "")),
                metadata = mapOf(
                    "confidence" to 0.95,
                    "processing_time_ms" to 150
                )
            )
        } catch (e: Exception) {
            InferenceResult(
                outputs = emptyMap(),
                error = RunnerError("E101", e.message ?: "Runtime error", true, e)
            )
        }
    }

    override fun unload() {
        sherpaEngine?.release()
        sherpaEngine = null
    }

    override fun getCapabilities(): List<CapabilityType> = listOf(CapabilityType.ASR)
}
```

## ğŸ“‹ ä»‹é¢å¯¦ä½œè¦ç¯„

### âœ… å¿…é ˆéµå¾ªçš„è¦å‰‡

1. **è³‡æºç®¡ç†**
   - `load()` æˆåŠŸå¾Œå¿…é ˆèƒ½åŸ·è¡Œ `run()`
   - `unload()` å¾Œå¿…é ˆé‡‹æ”¾æ‰€æœ‰è³‡æº
   - æ”¯æ´å¤šæ¬¡ `load()/unload()` å¾ªç’°

2. **éŒ¯èª¤è™•ç†**
   - æ‰€æœ‰ç•°å¸¸å¿…é ˆè½‰æ›ç‚º `RunnerError`
   - ä¸å¾—æ‹‹å‡ºæœªæ•æ‰çš„ä¾‹å¤–åˆ°ä¸Šå±¤
   - éŒ¯èª¤ç¢¼å¿…é ˆéµå¾ª [éŒ¯èª¤ç¢¼è¦ç¯„](../05-Error-Handling/error-codes.md)

3. **åŸ·è¡Œç·’å®‰å…¨**
   - å¦‚æœä¸æ˜¯ thread-safeï¼Œå¿…é ˆåœ¨ RunnerSpec ä¸­æ¨™æ˜
   - å»ºè­°ä½¿ç”¨ `@ThreadSafe` æˆ– `@NotThreadSafe` è¨»è§£

4. **æ•ˆèƒ½è¦æ±‚**
   - `run()` æ–¹æ³•ä¸æ‡‰é˜»å¡è¶…éé…ç½®çš„ timeout æ™‚é–“
   - å¤§å‹è³‡æºè¼‰å…¥æ‡‰åœ¨ `load()` éšæ®µå®Œæˆ

### âš ï¸ é™åˆ¶èˆ‡æ³¨æ„äº‹é …

- **ç¦æ­¢ç›´æ¥ JNI èª¿ç”¨**: æ‰€æœ‰ native æ“ä½œå¿…é ˆç¶“ç”± `RuntimeEngine`
- **è³‡æ–™æ ¼å¼é©—è­‰**: è¼¸å…¥è³‡æ–™æ ¼å¼éŒ¯èª¤æ‡‰å›å‚³ E401 éŒ¯èª¤ç¢¼  
- **è¨˜æ†¶é«”ç®¡ç†**: é¿å…è¨˜æ†¶é«”æ´©æ¼ï¼Œç‰¹åˆ¥æ˜¯ native è³‡æº
- **æ—¥èªŒè¨˜éŒ„**: é‡è¦æ“ä½œæ‡‰è¨˜éŒ„é©ç•¶çš„ log ä»¥ä¾¿é™¤éŒ¯

## ğŸ”— ç›¸é—œç« ç¯€

- **éŒ¯èª¤è™•ç†**: [éŒ¯èª¤ç¢¼å®šç¾©](../05-Error-Handling/error-codes.md) - çµ±ä¸€éŒ¯èª¤ç¢¼è¦ç¯„
- **èƒ½åŠ›å°æ‡‰**: [Capability å°æ‡‰è¡¨](./capability-mapping.md) - Runner èˆ‡èƒ½åŠ›çš„æ˜ å°„é—œä¿‚
- **è©³ç´°è¦æ ¼**: [Runner è¦æ ¼è¡¨](./runner-specifications.md) - å„ Runner çš„è©³ç´°è¦æ ¼
- **æ¨¡å‹é…ç½®**: [æ¨¡å‹é…ç½®è¦ç¯„](../03-Models/model-config-specification.md) - ModelConfig æ ¼å¼å®šç¾©

## ğŸ’¡ æœ€ä½³å¯¦å‹™å»ºè­°

### ğŸ¯ æ•ˆèƒ½å„ªåŒ–
- é å…ˆè¼‰å…¥å¸¸ç”¨è³‡æºï¼Œå»¶é²è¼‰å…¥æ¬¡è¦è³‡æº
- ä½¿ç”¨ç‰©ä»¶æ± é‡ç”¨æ˜‚è²´çš„ç‰©ä»¶
- åˆç†è¨­ç½® timeout é¿å…ç„¡é™ç­‰å¾…

### ğŸ›¡ï¸ ç©©å®šæ€§ä¿è­‰
- å¯¦ä½œå¥å…¨çš„è¼¸å…¥é©—è­‰
- æä¾›æœ‰æ„ç¾©çš„éŒ¯èª¤è¨Šæ¯
- æ”¯æ´ graceful degradation

### ğŸ”§ å¯ç¶­è­·æ€§
- æ¸…æ¥šçš„ç¨‹å¼ç¢¼è¨»è§£èˆ‡æ–‡ä»¶
- çµ±ä¸€çš„å‘½åæ…£ä¾‹
- é©ç•¶çš„å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡

---

ğŸ“ **è¿”å›**: [Interfaces é¦–é ](./README.md) | **ä¸‹ä¸€ç¯‡**: [èƒ½åŠ›å°æ‡‰è¡¨](./capability-mapping.md)

## ğŸ§ª Mock Runner å¯¦ä½œæŒ‡å—

### Mock Runner è¨­è¨ˆåŸå‰‡

åœ¨é–‹ç™¼å’Œæ¸¬è©¦éšæ®µï¼ŒMock Runner å¿…é ˆèƒ½å¤ ï¼š
1. **æ¨¡æ“¬çœŸå¯¦ Runner çš„è¡Œç‚ºæ¨¡å¼**
2. **æä¾›å¯é æ¸¬ä¸”å¯é…ç½®çš„å›æ‡‰**
3. **æ”¯æ´æ€§èƒ½æ¸¬è©¦å’Œå£“åŠ›æ¸¬è©¦**
4. **é©—è­‰ Runner æ¶æ§‹çš„æ“´å±•æ€§**

### MockLLMRunner å¯¦ä½œç¯„ä¾‹

```kotlin
class MockLLMRunner : BaseRunner, StreamingRunner {
    
    private val predefinedResponses = listOf(
        "é€™æ˜¯ä¸€å€‹æ¨¡æ“¬çš„ LLM å›æ‡‰ã€‚",
        "æˆ‘æ­£åœ¨ä½¿ç”¨ Mock Runner é€²è¡Œæ¸¬è©¦ã€‚",
        "AI Router æ¶æ§‹å·¥ä½œæ­£å¸¸ã€‚"
    )
    
    private var isLoaded = false
    private val responseDelay = 100L // æ¨¡æ“¬æ¨è«–å»¶é²
    
    override fun load(config: ModelConfig): Boolean {
        // æ¨¡æ“¬è¼‰å…¥æ™‚é–“
        Thread.sleep(500)
        isLoaded = true
        return true
    }
    
    override fun run(input: InferenceRequest, stream: Boolean): InferenceResult {
        if (!isLoaded) {
            return InferenceResult(
                outputs = emptyMap(),
                error = RunnerError("E001", "Model not loaded", true)
            )
        }
        
        val prompt = input.inputs["text"] as? String ?: ""
        val response = selectResponseFor(prompt)
        
        return if (stream) {
            streamResponse(response, input.sessionId)
        } else {
            InferenceResult(
                outputs = mapOf("text" to response),
                metadata = mapOf(
                    "model" to "mock-llm-v1",
                    "processing_time_ms" to responseDelay,
                    "tokens" to response.split(" ").size
                )
            )
        }
    }
    
    override fun runStream(
        input: InferenceRequest,
        onResult: (InferenceResult) -> Unit,
        onComplete: () -> Unit,
        onError: (Throwable) -> Unit
    ) {
        val prompt = input.inputs["text"] as? String ?: ""
        val response = selectResponseFor(prompt)
        val words = response.split(" ")
        
        // æ¨¡æ“¬ä¸²æµå›æ‡‰
        words.forEachIndexed { index, word ->
            Thread.sleep(responseDelay)
            
            val partialText = words.take(index + 1).joinToString(" ")
            val isPartial = index < words.size - 1
            
            onResult(InferenceResult(
                outputs = mapOf("text" to partialText),
                metadata = mapOf("partial_tokens" to index + 1),
                partial = isPartial
            ))
        }
        
        onComplete()
    }
    
    override fun unload() {
        isLoaded = false
    }
    
    override fun getCapabilities(): List<CapabilityType> = listOf(CapabilityType.LLM)
    
    private fun selectResponseFor(prompt: String): String {
        return when {
            prompt.contains("æ¸¬è©¦", ignoreCase = true) -> 
                "é€™æ˜¯ä¸€å€‹æ¸¬è©¦å›æ‡‰ï¼Œç”¨æ–¼é©—è­‰ Mock Runner çš„åŠŸèƒ½ã€‚"
            prompt.contains("éŒ¯èª¤", ignoreCase = true) -> 
                throw RuntimeException("æ¨¡æ“¬éŒ¯èª¤ï¼šé€™æ˜¯æ¸¬è©¦ç”¨çš„éŒ¯èª¤æƒ…æ³ã€‚")
            else -> predefinedResponses.random()
        }
    }
    
    private fun streamResponse(text: String, sessionId: String): InferenceResult {
        // éä¸²æµæ¨¡å¼ä¸‹çš„å®Œæ•´å›æ‡‰
        return InferenceResult(
            outputs = mapOf("text" to text),
            metadata = mapOf(
                "session_id" to sessionId,
                "stream_mode" to false
            )
        )
    }
}
```

### MockASRRunner å¯¦ä½œç¯„ä¾‹

```kotlin
class MockASRRunner : BaseRunner, StreamingRunner {
    
    private val mockTranscriptions = mapOf(
        "test_audio_1" to "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦éŸ³æª”ã€‚",
        "test_audio_2" to "AI Router èªéŸ³è­˜åˆ¥åŠŸèƒ½æ¸¬è©¦ã€‚",
        "default" to "é€™æ˜¯é è¨­çš„èªéŸ³è­˜åˆ¥çµæœã€‚"
    )
    
    override fun run(input: InferenceRequest, stream: Boolean): InferenceResult {
        val audioData = input.inputs["audio"] as? ByteArray
        val audioId = input.inputs["audio_id"] as? String ?: "default"
        
        if (audioData == null) {
            return InferenceResult(
                outputs = emptyMap(),
                error = RunnerError("E401", "Audio data required", false)
            )
        }
        
        // æ¨¡æ“¬éŸ³æª”è™•ç†æ™‚é–“
        Thread.sleep(300)
        
        val transcription = mockTranscriptions[audioId] ?: mockTranscriptions["default"]!!
        
        return InferenceResult(
            outputs = mapOf("text" to transcription),
            metadata = mapOf(
                "confidence" to 0.95,
                "processing_time_ms" to 300,
                "audio_length_ms" to audioData.size * 8 // æ¨¡æ“¬éŸ³æª”é•·åº¦
            )
        )
    }
    
    override fun runStream(
        input: InferenceRequest,
        onResult: (InferenceResult) -> Unit,
        onComplete: () -> Unit,
        onError: (Throwable) -> Unit
    ) {
        val audioId = input.inputs["audio_id"] as? String ?: "default"
        val fullTranscription = mockTranscriptions[audioId] ?: mockTranscriptions["default"]!!
        val words = fullTranscription.split("ã€‚", "ï¼Œ", " ").filter { it.isNotBlank() }
        
        // æ¨¡æ“¬å³æ™‚èªéŸ³è­˜åˆ¥
        words.forEachIndexed { index, segment ->
            Thread.sleep(200) // æ¨¡æ“¬è™•ç†æ¯å€‹èªéŸ³ç‰‡æ®µçš„æ™‚é–“
            
            val partialResult = words.take(index + 1).joinToString("")
            val isPartial = index < words.size - 1
            
            onResult(InferenceResult(
                outputs = mapOf("text" to partialResult),
                metadata = mapOf(
                    "confidence" to (0.7 + index * 0.05).coerceAtMost(0.95),
                    "segment_index" to index
                ),
                partial = isPartial
            ))
        }
        
        onComplete()
    }
    
    override fun getCapabilities(): List<CapabilityType> = listOf(CapabilityType.ASR)
}
```

### Mock Runner æ¸¬è©¦è¦æ±‚

#### åŠŸèƒ½æ¸¬è©¦
- âœ… **åŸºæœ¬æ¨è«–**ï¼šæ­£ç¢ºè™•ç†è¼¸å…¥ä¸¦è¿”å›é æœŸè¼¸å‡º
- âœ… **ä¸²æµè™•ç†**ï¼šæ”¯æ´éƒ¨åˆ†çµæœçš„é€æ­¥è¿”å›
- âœ… **éŒ¯èª¤è™•ç†**ï¼šæ¨¡æ“¬å„ç¨®éŒ¯èª¤æƒ…æ³ä¸¦æ­£ç¢ºå›å ±
- âœ… **è³‡æºç®¡ç†**ï¼šæ­£ç¢ºåŸ·è¡Œè¼‰å…¥å’Œå¸è¼‰æ“ä½œ

#### æ•ˆèƒ½æ¸¬è©¦
- âœ… **å»¶é²æ¨¡æ“¬**ï¼šæ¨¡æ“¬çœŸå¯¦ Runner çš„è™•ç†æ™‚é–“
- âœ… **ä½µç™¼è™•ç†**ï¼šæ”¯æ´å¤šå€‹åŒæ™‚è«‹æ±‚
- âœ… **è¨˜æ†¶é«”ç®¡ç†**ï¼šé¿å…è¨˜æ†¶é«”æ´©æ¼

#### æ“´å±•æ€§æ¸¬è©¦
- âœ… **å‹•æ…‹è¨»å†Š**ï¼šå¯åœ¨é‹è¡Œæ™‚è¨»å†Šå’Œè¨»éŠ·
- âœ… **é…ç½®è®Šæ›´**ï¼šæ”¯æ´é‹è¡Œæ™‚é…ç½®æ›´æ–°
- âœ… **Fallback é©—è­‰**ï¼šæ­£ç¢ºè§¸ç™¼ fallback æ©Ÿåˆ¶

### Mock Runner é…ç½®ç¯„ä¾‹

```kotlin
// åœ¨ AI Router Service ä¸­è¨»å†Š Mock Runners
class AIRouterService {
    
    private fun registerMockRunners() {
        val runnerRegistry = RunnerRegistry.getInstance()
        
        // è¨»å†Šå„ç¨® Mock Runners
        runnerRegistry.register("MockLLMRunner") { MockLLMRunner() }
        runnerRegistry.register("MockASRRunner") { MockASRRunner() }
        runnerRegistry.register("MockTTSRunner") { MockTTSRunner() }
        runnerRegistry.register("MockVLMRunner") { MockVLMRunner() }
        runnerRegistry.register("MockGuardrailRunner") { MockGuardrailRunner() }
        
        // è¨­å®šé è¨­çš„ Runner é¸æ“‡
        val aiEngineManager = AIEngineManager()
        aiEngineManager.setDefaultRunners(mapOf(
            CapabilityType.LLM to "MockLLMRunner",
            CapabilityType.ASR to "MockASRRunner",
            CapabilityType.TTS to "MockTTSRunner",
            CapabilityType.VLM to "MockVLMRunner",
            CapabilityType.GUARDIAN to "MockGuardrailRunner"
        ))
    }
}
```

### é©—è­‰ Runner æ“´å±•æ€§çš„æ¸¬è©¦æ¡ˆä¾‹

```kotlin
@Test
fun testRunnerExtensibility() {
    val registry = RunnerRegistry()
    val engineManager = AIEngineManager(registry)
    
    // 1. æ¸¬è©¦æ–° Runner çš„å‹•æ…‹è¨»å†Š
    val customRunner = object : BaseRunner {
        override fun load(config: ModelConfig) = true
        override fun run(input: InferenceRequest, stream: Boolean) = 
            InferenceResult(outputs = mapOf("text" to "Custom response"))
        override fun unload() {}
        override fun getCapabilities() = listOf(CapabilityType.LLM)
    }
    
    registry.register("CustomLLMRunner") { customRunner }
    
    // 2. é©—è­‰æ–° Runner èƒ½è¢«æ­£ç¢ºé¸æ“‡å’Œä½¿ç”¨
    val request = InferenceRequest(
        sessionId = "test",
        inputs = mapOf("text" to "test prompt")
    )
    
    val result = engineManager.process(request, CapabilityType.LLM, "CustomLLMRunner")
    assertEquals("Custom response", result.outputs["text"])
    
    // 3. æ¸¬è©¦ Runner çš„ç§»é™¤
    registry.unregister("CustomLLMRunner")
    assertThrows<RunnerNotFoundException> {
        engineManager.process(request, CapabilityType.LLM, "CustomLLMRunner")
    }
}
``` 
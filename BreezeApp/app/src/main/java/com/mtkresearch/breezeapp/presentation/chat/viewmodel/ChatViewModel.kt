package com.mtkresearch.breezeapp.presentation.chat.viewmodel

import android.app.Application
import android.content.Context
import android.text.Html
import android.util.Log
import androidx.lifecycle.viewModelScope
import kotlinx.coroutines.delay
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import com.mtkresearch.breezeapp.presentation.common.base.BaseViewModel
import com.mtkresearch.breezeapp.presentation.chat.model.ChatMessage
import com.mtkresearch.breezeapp.presentation.chat.model.ChatSession
import com.mtkresearch.breezeapp.domain.usecase.breezeapp.*
import com.mtkresearch.breezeapp.domain.usecase.settings.LoadRuntimeSettingsUseCase
import com.mtkresearch.breezeapp.domain.usecase.chat.LoadCurrentSessionUseCase
import com.mtkresearch.breezeapp.domain.usecase.chat.SaveCurrentSessionUseCase
import com.mtkresearch.breezeapp.domain.usecase.chat.ClearCurrentSessionUseCase
import com.mtkresearch.breezeapp.domain.repository.ChatRepository
import com.mtkresearch.breezeapp.domain.model.breezeapp.ConnectionState as BreezeAppConnectionState
import com.mtkresearch.breezeapp.domain.model.breezeapp.BreezeAppError
import com.mtkresearch.breezeapp.domain.model.breezeapp.AsrConfig
import com.mtkresearch.breezeapp.domain.model.breezeapp.AsrMode
import com.mtkresearch.breezeapp.core.permission.OverlayPermissionManager
import com.mtkresearch.breezeapp.core.audio.AudioRecorder
import com.mtkresearch.breezeapp.core.audio.AudioRecordingResult
import com.mtkresearch.breezeapp.R
import com.mtkresearch.breezeapp.presentation.chat.fragment.ChatFragment.Companion.TAG
import dagger.hilt.android.lifecycle.HiltViewModel
import kotlinx.coroutines.Job
import kotlinx.coroutines.launch
import kotlinx.coroutines.withTimeoutOrNull
import kotlinx.coroutines.flow.onCompletion
import javax.inject.Inject

/**
 * èŠå¤©ViewModel
 * 
 * åŠŸèƒ½ç‰¹è‰²:
 * - ç®¡ç†èŠå¤©è¨Šæ¯åˆ—è¡¨å’Œæœƒè©±ç‹€æ…‹
 * - è™•ç†ç”¨æˆ¶è¼¸å…¥å’ŒAIå›æ‡‰
 * - æ”¯æ´è¨Šæ¯é‡è©¦å’ŒéŒ¯èª¤è™•ç†
 * - æä¾›æ‰“å­—æŒ‡ç¤ºå™¨å’Œè¼‰å…¥ç‹€æ…‹
 * - æ•´åˆ BreezeApp Engine æä¾›çœŸå¯¦AIåŠŸèƒ½
 * 
 * éµå¾ª Clean Architecture åŸå‰‡:
 * - ä½¿ç”¨ UseCase è™•ç†æ¥­å‹™é‚è¼¯
 * - ä¿æŒ ViewModel çš„ UI å°å‘
 * - çµ±ä¸€çš„éŒ¯èª¤è™•ç†
 */
@HiltViewModel
class ChatViewModel @Inject constructor(
    private val application: Application,
    private val connectionUseCase: ConnectionUseCase,
    private val chatUseCase: ChatUseCase,
    private val streamingChatUseCase: StreamingChatUseCase,
    private val ttsUseCase: TtsUseCase,
    private val asrMicrophoneUseCase: AsrMicrophoneUseCase,
    private val asrFileUseCase: AsrFileUseCase,
    private val requestCancellationUseCase: RequestCancellationUseCase,
    private val overlayPermissionManager: OverlayPermissionManager,
    private val loadRuntimeSettingsUseCase: LoadRuntimeSettingsUseCase,
    private val loadCurrentSessionUseCase: LoadCurrentSessionUseCase = LoadCurrentSessionUseCase(DefaultChatRepository),
    private val saveCurrentSessionUseCase: SaveCurrentSessionUseCase = SaveCurrentSessionUseCase(DefaultChatRepository),
    private val clearCurrentSessionUseCase: ClearCurrentSessionUseCase = ClearCurrentSessionUseCase(DefaultChatRepository)
) : BaseViewModel() {

    private val tag: String = "ChatViewModel"
    private var microphoneStreamingJob: Job? = null
    private var isUserStoppingMicrophone: Boolean = false
    private val audioRecorder = AudioRecorder()
    
    companion object {
        private const val SAMPLE_RATE = 16000 // 16kHz audio sample rate
    }

    /**
     * å–å¾—æ‡‰ç”¨ç¨‹å¼å­—ä¸²è³‡æº
     */
    private fun getApplicationString(resId: Int): String {
        return Html.fromHtml(application.getString(resId), Html.FROM_HTML_MODE_COMPACT).toString()
    }

    // ç•¶å‰èŠå¤©æœƒè©±
    private val _currentSession = MutableStateFlow(ChatSession())
    val currentSession: StateFlow<ChatSession> = _currentSession.asStateFlow()

    // èŠå¤©è¨Šæ¯åˆ—è¡¨
    private val _messages = MutableStateFlow<List<ChatMessage>>(emptyList())
    val messages: StateFlow<List<ChatMessage>> = _messages.asStateFlow()

    // è¼¸å…¥æ¡†æ–‡å­—
    private val _inputText = MutableStateFlow("")
    val inputText: StateFlow<String> = _inputText.asStateFlow()

    // æ˜¯å¦å¯ä»¥ç™¼é€è¨Šæ¯
    private val _canSendMessage = MutableStateFlow(false)
    val canSendMessage: StateFlow<Boolean> = _canSendMessage.asStateFlow()

    // AIæ˜¯å¦æ­£åœ¨å›æ‡‰
    private val _isAIResponding = MutableStateFlow(false)
    val isAIResponding: StateFlow<Boolean> = _isAIResponding.asStateFlow()

    // èªéŸ³è­˜åˆ¥ç‹€æ…‹
    private val _isListening = MutableStateFlow(false)
    val isListening: StateFlow<Boolean> = _isListening.asStateFlow()

    // ASR æ¨¡å¼é…ç½®
    private val _asrConfig = MutableStateFlow(AsrConfig())
    val asrConfig: StateFlow<AsrConfig> = _asrConfig.asStateFlow()

    // é›¢ç·šéŒ„éŸ³é€²åº¦ (0.0 - 1.0)
    private val _recordingProgress = MutableStateFlow(0f)
    val recordingProgress: StateFlow<Float> = _recordingProgress.asStateFlow()

    // TTS æ’­æ”¾ç‹€æ…‹ - ç•¶å‰æ­£åœ¨æ’­æ”¾TTSçš„è¨Šæ¯ID (nullè¡¨ç¤ºæ²’æœ‰æ’­æ”¾)
    private val _currentlyPlayingMessageId = MutableStateFlow<String?>(null)
    val currentlyPlayingMessageId: StateFlow<String?> = _currentlyPlayingMessageId.asStateFlow()

    // TTS æ’­æ”¾ä»»å‹™
    private var currentTtsJob: Job? = null

    // æ­·å²æœƒè©±åˆ—è¡¨ (ç°¡åŒ–å¯¦ä½œ)
    private val _chatSessions = MutableStateFlow<List<ChatSession>>(emptyList())
    val chatSessions: StateFlow<List<ChatSession>> = _chatSessions.asStateFlow()

    // BreezeApp Engine é€£æ¥ç‹€æ…‹
    private val _connectionState = MutableStateFlow<BreezeAppConnectionState>(BreezeAppConnectionState.Disconnected)
    val connectionState: StateFlow<BreezeAppConnectionState> = _connectionState.asStateFlow()

    // ç•¶å‰ä¸²æµè«‹æ±‚ID
    private var currentStreamingRequestId: String? = null

    init {
        // è¼‰å…¥ä¹‹å‰çš„æœƒè©±æˆ–åˆå§‹åŒ–æ–°æœƒè©±
        loadOrInitializeSession()
        // ç¢ºä¿åˆå§‹ç‹€æ…‹æ­£ç¢º
        updateCanSendMessageState()
        // åˆå§‹åŒ– BreezeApp Engine é€£æ¥
        initializeBreezeAppEngine()
    }

    /**
     * æ›´æ–°è¼¸å…¥æ–‡å­—
     */
    fun updateInputText(text: String) {
        _inputText.value = text
        updateCanSendMessageState()
    }

    /**
     * æ›´æ–°canSendMessageç‹€æ…‹
     */
    private fun updateCanSendMessageState() {
        _canSendMessage.value = _inputText.value.trim().isNotEmpty() && !_isAIResponding.value && !_isListening.value
    }

    /**
     * ç™¼é€è¨Šæ¯
     */
    fun sendMessage(text: String = _inputText.value) {
        val messageText = text.trim()
        // æª¢æŸ¥æ˜¯å¦åœ¨èªéŸ³è­˜åˆ¥ä¸­æˆ–AIå›æ‡‰ä¸­ï¼Œå¦‚æœæ˜¯å‰‡ç›´æ¥è¿”å›ä¸åŸ·è¡Œ
        if (messageText.isEmpty() || _isAIResponding.value || _isListening.value) return

        if (!validateInput(messageText.isNotBlank(), getApplicationString(R.string.error_message_cannot_be_empty))) return

        launchSafely(showLoading = false) {
            // å‰µå»ºç”¨æˆ¶è¨Šæ¯ - ç›´æ¥è¨­ç‚ºæ­£å¸¸ç‹€æ…‹
            val userMessage = ChatMessage(
                text = messageText,
                isFromUser = true,
                state = ChatMessage.MessageState.NORMAL
            )

            // æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°åˆ—è¡¨
            addMessage(userMessage)
            
            // æ¸…ç©ºè¼¸å…¥æ¡†
            _inputText.value = ""
            _canSendMessage.value = false
            _isAIResponding.value = true

            // é–‹å§‹AIå›æ‡‰æµç¨‹
            generateAIResponse(messageText)
        }
    }

    /**
     * ç”ŸæˆAIå›æ‡‰ (æ•´åˆ BreezeApp Engine)
     */
    private suspend fun generateAIResponse(userInput: String) {
        try {
            // æª¢æŸ¥ BreezeApp Engine é€£æ¥ç‹€æ…‹
            if (connectionUseCase.isConnected()) {
                // ä½¿ç”¨çœŸå¯¦çš„ BreezeApp Engine
                generateAIResponseWithBreezeApp(userInput)
            } else {
                // å›é€€åˆ°æ¨¡æ“¬å›æ‡‰
                generateMockAIResponse(userInput)
            }
        } catch (e: Exception) {
            handleAIResponseError(e)
        } finally {
            _isAIResponding.value = false
            // AIå›æ‡‰å®Œæˆå¾Œï¼Œæ›´æ–°canSendMessageç‹€æ…‹
            updateCanSendMessageState()
        }
    }
    
    /**
     * ç”Ÿæˆæ¨¡æ“¬AIå›æ‡‰ (å›é€€æ–¹æ¡ˆ)
     */
    private suspend fun generateMockAIResponse(userInput: String) {
        try {
            // å‰µå»ºAIå›æ‡‰è¨Šæ¯ (åˆå§‹ç‚ºè¼‰å…¥ç‹€æ…‹)
            val aiMessage = ChatMessage(
                text = getApplicationString(R.string.ai_thinking_message),
                isFromUser = false,
                state = ChatMessage.MessageState.TYPING
            )
            addMessage(aiMessage)

            // æ¨¡æ“¬AIæ€è€ƒæ™‚é–“
            delay((1500 + (0..1000).random()).toLong())

            // ç”Ÿæˆæ¨¡æ“¬å›æ‡‰
            val response = generateMockResponse(userInput)
            
            // æ›´æ–°AIè¨Šæ¯
            updateMessageText(aiMessage.id, response)
            updateMessageState(aiMessage.id, ChatMessage.MessageState.NORMAL)

            // æ›´æ–°æœƒè©±
            updateCurrentSession()
            
            setSuccess(getApplicationString(R.string.ai_response_completed_simulation))

        } catch (e: Exception) {
            handleAIResponseError(e)
        }
    }

    /**
     * è™•ç†AIå›æ‡‰éŒ¯èª¤
     */
    private suspend fun handleAIResponseError(error: Throwable) {
        // æ‰¾åˆ°æœ€å¾Œä¸€æ¢AIè¨Šæ¯ä¸¦æ¨™è¨˜ç‚ºéŒ¯èª¤
        val lastAIMessage = _messages.value.lastOrNull { !it.isFromUser }
        lastAIMessage?.let { message ->
            updateMessageText(message.id, getApplicationString(R.string.ai_response_error_retry))
            updateMessageState(message.id, ChatMessage.MessageState.ERROR)
        }
        
        setError(getApplicationString(R.string.ai_response_failed).format(error.message))
    }

    /**
     * é‡è©¦æœ€å¾Œä¸€æ¬¡AIå›æ‡‰
     */
    fun retryLastAIResponse() {
        val lastUserMessage = _messages.value.lastOrNull { it.isFromUser }
        if (lastUserMessage != null && !_isAIResponding.value) {
            launchSafely(showLoading = false) {
                _isAIResponding.value = true
                _canSendMessage.value = false
                
                // æ‰¾åˆ°ä¸¦æ›´æ–°æœ€å¾Œä¸€æ¢AIè¨Šæ¯ï¼Œè€Œä¸æ˜¯ç§»é™¤å®ƒ
                val lastAIMessage = _messages.value.lastOrNull { !it.isFromUser }
                if (lastAIMessage != null) {
                    // é‡ç½®AIè¨Šæ¯ç‚ºè¼‰å…¥ç‹€æ…‹
                    updateMessageText(lastAIMessage.id, getApplicationString(R.string.ai_thinking_message))
                    updateMessageState(lastAIMessage.id, ChatMessage.MessageState.TYPING)
                    
                    // æ¨¡æ“¬AIæ€è€ƒæ™‚é–“
                    delay((1500 + (0..1000).random()).toLong())
                    
                    // ç”Ÿæˆæ–°çš„å›æ‡‰
                    val response = generateMockResponse(lastUserMessage.text)
                    updateMessageText(lastAIMessage.id, response)
                    updateMessageState(lastAIMessage.id, ChatMessage.MessageState.NORMAL)
                    
                    setSuccess(getApplicationString(R.string.ai_response_retry_completed))
                } else {
                    // å¦‚æœæ²’æœ‰AIè¨Šæ¯ï¼Œå‰µå»ºæ–°çš„
                    generateAIResponse(lastUserMessage.text)
                }
                
                _isAIResponding.value = false
                updateCanSendMessageState()
            }
        }
    }

    // Overlay permission status
    private val _overlayPermissionGranted = MutableStateFlow(false)
    val overlayPermissionGranted: StateFlow<Boolean> = _overlayPermissionGranted.asStateFlow()

    /**
     * Check overlay permission status
     */
    fun checkOverlayPermission(context: Context) {
        _overlayPermissionGranted.value = overlayPermissionManager.isOverlayPermissionGranted(context)
        Log.d(tag, "Overlay permission status: ${_overlayPermissionGranted.value}")
    }

    /**
     * Toggle ASR mode between available modes based on configuration
     */
    fun toggleAsrMode() {
        val currentConfig = _asrConfig.value
        
        // Only allow toggle if configuration permits it
        if (!currentConfig.availabilityConfig.allowModeToggle) {
            val availableModes = currentConfig.availabilityConfig.getAvailableModes()
            val modeText = if (availableModes.size == 1) {
                when (availableModes.first()) {
                    AsrMode.ONLINE_STREAMING -> getApplicationString(R.string.asr_mode_online_streaming)
                    AsrMode.OFFLINE_FILE -> getApplicationString(R.string.asr_mode_offline_file)
                }
            } else getApplicationString(R.string.asr_mode_multiple)
            setSuccess(getApplicationString(R.string.asr_mode_fixed_to).format(modeText))
            return
        }
        
        val nextMode = currentConfig.getNextAvailableMode()
        if (nextMode != null) {
            _asrConfig.value = currentConfig.copy(mode = nextMode)
            
            val modeText = when (nextMode) {
                AsrMode.ONLINE_STREAMING -> getApplicationString(R.string.asr_mode_online_streaming)
                AsrMode.OFFLINE_FILE -> getApplicationString(R.string.asr_mode_offline_file)
            }
            setSuccess(getApplicationString(R.string.asr_mode_switched_to).format(modeText))
        } else {
            setSuccess(getApplicationString(R.string.asr_mode_no_switchable))
        }
    }

    /**
     * Request overlay permission for microphone functionality
     */
    fun requestOverlayPermissionForMicrophone(context: Context) {
        if (overlayPermissionManager.isOverlayPermissionGranted(context)) {
            _overlayPermissionGranted.value = true
            setSuccess(getApplicationString(R.string.overlay_permission_granted))
            return
        }
        
        Log.d(tag, "Requesting overlay permission for microphone functionality")
        overlayPermissionManager.requestOverlayPermission(context)
    }

    /**
     * é–‹å§‹èªéŸ³è­˜åˆ¥ - æ”¯æ´ç·šä¸Šä¸²æµå’Œé›¢ç·šæª”æ¡ˆå…©ç¨®æ¨¡å¼
     */
    fun startVoiceRecognition(context: Context? = null) {
        if (_isListening.value || _isAIResponding.value) return

        // Check overlay permission before starting microphone
        context?.let { ctx ->
            if (!overlayPermissionManager.isOverlayPermissionGranted(ctx)) {
                Log.w(tag, "âš ï¸ Overlay permission not granted - this may cause FGS_MICROPHONE to fail")
                setError(getApplicationString(R.string.overlay_permission_required_for_voice))
                return
            }
        }

        // Cancel any existing microphone streaming job
        microphoneStreamingJob?.cancel()

        // Choose ASR mode based on availability configuration
        val config = _asrConfig.value
        
        // Ensure current mode is available, fallback to default if not
        val modeToUse = if (config.isCurrentModeAvailable()) {
            config.mode
        } else {
            val defaultMode = config.availabilityConfig.getDefaultMode()
            _asrConfig.value = config.copy(mode = defaultMode)
            defaultMode
        }
        
        when (modeToUse) {
            AsrMode.ONLINE_STREAMING -> {
                if (config.availabilityConfig.onlineStreamingEnabled) {
                    startOnlineStreamingAsr()
                } else {
                    Log.w(tag, "Online streaming ASR requested but not enabled, falling back to offline")
                    startOfflineFileAsr()
                }
            }
            AsrMode.OFFLINE_FILE -> {
                startOfflineFileAsr()
            }
        }
    }

    /**
     * é–‹å§‹ç·šä¸Šä¸²æµ ASR æ¨¡å¼
     */
    private fun startOnlineStreamingAsr() {
        microphoneStreamingJob = viewModelScope.launch {
            try {
                Log.d(tag, "ğŸ¤ Starting ONLINE streaming ASR...")
                Log.d(tag, "ğŸ”„ Engine will handle microphone recording directly")
                Log.d(tag, "âœ… Overlay permission verified before starting")
                
                // Set recording state to true
                _isListening.value = true
                
                Log.d(tag, "ğŸ”„ Sending microphone mode ASR request to engine...")
                Log.d(tag, "   â””â”€â”€ Engine will open microphone and process audio directly")
                
                asrMicrophoneUseCase.execute(_asrConfig.value.language).collect { response ->
                    // Update input text with ASR result for real-time display
                    updateInputText(response.text)
                    
                    if (response.isChunk) {
                        Log.d(tag, "ğŸ“¡ [Online Streaming] ${response.text}")
                    } else {
                        Log.d(tag, "âœ… [Online Streaming Final] ${response.text}")
                        // Final result received, but keep recording state until user stops
                        // The recording will continue until the user explicitly stops it
                    }
                    
                    // Show additional details if available
                    response.language?.let { lang ->
                        Log.d(tag, "   â””â”€â”€ Detected language: $lang")
                    }
                    
                    response.segments?.forEach { segment ->
                        Log.d(tag, "   â””â”€â”€ Segment: ${segment.text} (${segment.start}s - ${segment.end}s)")
                    }
                    
                    // Note: Flow will continue until cancelled by stopMicrophoneStreaming()
                    // We don't stop recording automatically on final result
                    // User must explicitly stop the recording
                }
                
            } catch (e: kotlinx.coroutines.CancellationException) {
                // Check if this was user-initiated (most robust approach)
                if (isUserStoppingMicrophone) {
                    Log.d(tag, "âœ… Online streaming ASR stopped by user")
                } else {
                    Log.d(tag, "âš ï¸ Online streaming ASR cancelled unexpectedly")
                }
                _isListening.value = false
            } catch (e: Exception) {
                Log.d(tag, "âŒ Failed to start online streaming ASR: ${e.message}")
                _isListening.value = false
            } finally {
                // Ensure recording state is reset when job completes
                _isListening.value = false
                microphoneStreamingJob = null
                isUserStoppingMicrophone = false // Reset flag
            }
        }
    }

    /**
     * é–‹å§‹é›¢ç·šæª”æ¡ˆ ASR æ¨¡å¼ - ROBUST VERSION with guaranteed audio processing
     */
    private fun startOfflineFileAsr() {
        microphoneStreamingJob = viewModelScope.launch {
            var audioProcessed = false
            var lastValidAudio: ByteArray? = null
            
            try {
                Log.d(tag, "ğŸ¤ Starting OFFLINE file-based ASR (ROBUST MODE)...")
                Log.d(tag, "ğŸ”„ Recording audio locally first, then processing through engine")
                
                // Set recording state to true
                _isListening.value = true
                _recordingProgress.value = 0f
                
                // Start audio recording with robust handling
                audioRecorder.recordAudio(_asrConfig.value.maxRecordingDurationMs)
                    .onCompletion { cause ->
                        // ROBUST: Handle flow completion regardless of cause
                        Log.d(tag, "ğŸ”„ [Offline] Audio recording flow completed. Cause: ${cause?.message ?: "Natural completion"}")
                        
                        // If audio wasn't processed yet and we have valid audio, process it now
                        if (!audioProcessed && lastValidAudio != null && lastValidAudio!!.size > SAMPLE_RATE * 2) {
                            Log.d(tag, "ğŸ›¡ï¸ [Offline] ROBUST FALLBACK: Processing audio from completion handler")
                            viewModelScope.launch {
                                processOfflineAudioFileRobust(lastValidAudio!!)
                                audioProcessed = true
                            }
                        }
                    }
                    .collect { result ->
                        when (result) {
                            is AudioRecordingResult.Started -> {
                                Log.d(tag, "ğŸ™ï¸ [Offline] Audio recording started")
                            }
                            is AudioRecordingResult.Recording -> {
                                _recordingProgress.value = result.progress
                                Log.d(tag, "ğŸ™ï¸ [Offline] Recording progress: ${(result.progress * 100).toInt()}%")
                            }
                            is AudioRecordingResult.Completed -> {
                                Log.d(tag, "ğŸ™ï¸ [Offline] Audio recording completed: ${result.audioData.size} bytes")
                                _recordingProgress.value = 1f
                                lastValidAudio = result.audioData
                                
                                // Immediately process the recorded audio through ASR
                                Log.d(tag, "ğŸš€ [Offline] ROBUST: Immediately processing completed audio")
                                processOfflineAudioFileRobust(result.audioData)
                                audioProcessed = true
                            }
                            is AudioRecordingResult.Cancelled -> {
                                Log.d(tag, "ğŸ™ï¸ [Offline] Audio recording cancelled by user: ${result.partialAudioData.size} bytes")
                                lastValidAudio = result.partialAudioData
                                
                                // Immediately process partial audio if there's enough data
                                if (result.partialAudioData.size > SAMPLE_RATE * 2) {
                                    Log.d(tag, "ğŸš€ [Offline] ROBUST: Immediately processing cancelled audio")
                                    processOfflineAudioFileRobust(result.partialAudioData)
                                    audioProcessed = true
                                } else {
                                    Log.d(tag, "â„¹ï¸ [Offline] Not enough audio data to process (${result.partialAudioData.size} bytes)")
                                    setSuccess(getApplicationString(R.string.recording_cancelled_too_short))
                                    _isListening.value = false
                                    audioProcessed = true // Mark as processed to avoid fallback
                                }
                            }
                            is AudioRecordingResult.Error -> {
                                Log.e(tag, "âŒ [Offline] Recording error: ${result.message}")
                                setError(getApplicationString(R.string.recording_failed).format(result.message))
                                _isListening.value = false
                                audioProcessed = true // Mark as processed to avoid fallback
                            }
                        }
                    }
                
            } catch (e: kotlinx.coroutines.CancellationException) {
                Log.d(tag, "ğŸ›¡ï¸ [Offline] ROBUST: Handling cancellation exception")
                
                if (isUserStoppingMicrophone && !audioProcessed && lastValidAudio != null) {
                    Log.d(tag, "ğŸ›¡ï¸ [Offline] ROBUST RECOVERY: Processing audio despite cancellation")
                    if (lastValidAudio!!.size > SAMPLE_RATE * 2) {
                        processOfflineAudioFileRobust(lastValidAudio!!)
                        audioProcessed = true
                    }
                }
                
                audioRecorder.stopRecording()
                _isListening.value = false
            } catch (e: Exception) {
                Log.e(tag, "âŒ [Offline] ROBUST: Exception in ASR flow: ${e.message}")
                audioRecorder.stopRecording()
                _isListening.value = false
            } finally {
                // ROBUST: Final cleanup with guaranteed state reset
                Log.d(tag, "ğŸ›¡ï¸ [Offline] ROBUST: Final cleanup - audio processed: $audioProcessed")
                _isListening.value = false
                _recordingProgress.value = 0f
                microphoneStreamingJob = null
                isUserStoppingMicrophone = false
            }
        }
    }

    /**
     * è™•ç†é›¢ç·šéŒ„è£½çš„éŸ³é »æª”æ¡ˆ - ç«‹å³ç™¼é€åˆ° BreezeApp Engine (ROBUST VERSION)
     */
    private suspend fun processOfflineAudioFileRobust(audioData: ByteArray) {
        var asrCompleted = false
        
        try {
            Log.d(tag, "ğŸš€ [ROBUST] Sending ${audioData.size} bytes to BreezeApp Engine ASR...")
            
            // Call AsrFileUseCase to send audio data to BreezeApp Engine with timeout protection
            withTimeoutOrNull(120000L) { // 120 second timeout
                asrFileUseCase.execute(audioData, _asrConfig.value.language).collect { response ->
                    // Update input text with ASR result
                    updateInputText(response.text)
                    
                    if (response.isChunk) {
                        Log.d(tag, "ğŸ“¡ [ROBUST Offline Chunk] ${response.text}")
                    } else {
                        Log.d(tag, "âœ… [ROBUST Offline Final] ${response.text}")
                        // ASR processing completed - reset listening state
                        _isListening.value = false
                        _recordingProgress.value = 0f
                        asrCompleted = true
                    }
                    
                    // Show additional details if available
                    response.language?.let { lang ->
                        Log.d(tag, "   â””â”€â”€ Detected language: $lang")
                    }
                    
                    response.segments?.forEach { segment ->
                        Log.d(tag, "   â””â”€â”€ Segment: ${segment.text} (${segment.start}s - ${segment.end}s)")
                    }
                }
            } ?: run {
                // Timeout occurred - cancel the engine request to stop breathing border
                Log.w(tag, "â±ï¸ [ROBUST] ASR processing timed out after 120 seconds")
                try {
                    val cancelled = requestCancellationUseCase.cancelLastRequest()
                    Log.d(tag, "â±ï¸ [ROBUST] Engine request cancellation result: $cancelled")
                } catch (e: Exception) {
                    Log.w(tag, "â±ï¸ [ROBUST] Failed to cancel engine request: ${e.message}")
                }
                setError(getApplicationString(R.string.voice_processing_timeout_retry))
                _isListening.value = false
                _recordingProgress.value = 0f
            }
            
        } catch (e: kotlinx.coroutines.CancellationException) {
            Log.d(tag, "ğŸ›¡ï¸ [ROBUST] ASR processing cancelled")
            _isListening.value = false
            _recordingProgress.value = 0f
        } catch (e: Exception) {
            Log.e(tag, "âŒ [ROBUST] Failed to process audio with BreezeApp Engine: ${e.message}")
            setError(getApplicationString(R.string.voice_processing_failed).format(e.message))
            _isListening.value = false
            _recordingProgress.value = 0f
        } finally {
            // ROBUST: Ensure UI state is always reset
            if (!asrCompleted) {
                Log.d(tag, "ğŸ›¡ï¸ [ROBUST] Ensuring UI state reset after processing")
                _isListening.value = false
                _recordingProgress.value = 0f
            }
        }
    }
    
    /**
     * è™•ç†é›¢ç·šéŒ„è£½çš„éŸ³é »æª”æ¡ˆ - ç«‹å³ç™¼é€åˆ° BreezeApp Engine (Legacy for compatibility)
     */
    private suspend fun processOfflineAudioFile(audioData: ByteArray) {
        // Delegate to robust version
        processOfflineAudioFileRobust(audioData)
    }

    /**
     * åœæ­¢èªéŸ³è­˜åˆ¥ - ULTIMATE ROBUST VERSION: Ensures audio processing before job cancellation
     */
    fun stopVoiceRecognition() {
        if (_isListening.value) {
            Log.d(tag, "ğŸ›‘ User stopping voice recognition...")
            isUserStoppingMicrophone = true
            
            // Immediate UI feedback - update state first for responsiveness
            _isListening.value = false
            _recordingProgress.value = 0f
            updateCanSendMessageState()
            
            // ROBUST: Stop audio recorder first to trigger controlled termination
            // This sets the manual stop flag which allows the flow to complete naturally
            if (_asrConfig.value.mode == AsrMode.OFFLINE_FILE) {
                Log.d(tag, "ğŸ›‘ [ULTIMATE ROBUST] Triggering controlled audio recorder stop...")
                audioRecorder.stopRecording()
                // The AudioRecorder will now emit the final result through its normal flow
                // and the collect loop will process it before the coroutine finishes
            } else {
                // For online streaming, cancel immediately
                Log.d(tag, "ğŸ›‘ Cancelling online streaming job immediately")
                microphoneStreamingJob?.cancel()
                microphoneStreamingJob = null
            }
            
            // Cancel any ongoing engine requests (non-blocking)
            viewModelScope.launch {
                try {
                    requestCancellationUseCase.cancelLastRequest()
                    Log.d(tag, "âœ… Engine request cancelled successfully")
                } catch (e: Exception) {
                    Log.w(tag, "âš ï¸ Failed to cancel engine request: ${e.message}")
                }
            }
            
            val currentMode = _asrConfig.value.mode
            val modeText = when (currentMode) {
                AsrMode.ONLINE_STREAMING -> getApplicationString(R.string.asr_mode_online_streaming)
                AsrMode.OFFLINE_FILE -> getApplicationString(R.string.asr_mode_offline_file)
            }
            setSuccess(getApplicationString(R.string.voice_recognition_stopped_immediately).format(modeText))
            
            Log.d(tag, "âœ… Voice recognition stopped with ultimate robust audio processing")
        }
    }

    /**
     * æ¸…ç©ºèŠå¤©è¨˜éŒ„
     */
    fun clearChat() {
        _messages.value = emptyList()
        _currentSession.value = ChatSession()
        _inputText.value = ""
        _canSendMessage.value = false
        _isAIResponding.value = false
        _isListening.value = false
        updateCanSendMessageState() // ç¢ºä¿ç‹€æ…‹ä¸€è‡´
        
        // æ¸…ç©ºrepositoryä¸­çš„æœƒè©±
        launchSafely(showLoading = false) {
            clearCurrentSessionUseCase()
        }
        
        setSuccess(getApplicationString(R.string.chat_history_cleared))
        // ä¸è‡ªå‹•é‡æ–°è¼‰å…¥æ­¡è¿è¨Šæ¯ï¼Œè®“æ¸¬è©¦å¯ä»¥é©—è­‰ç©ºç‹€æ…‹
    }

    /**
     * å‰µå»ºæ–°æœƒè©±
     */
    fun createNewSession() {
        // ä¿å­˜ç•¶å‰æœƒè©±
        if (_messages.value.isNotEmpty()) {
            val updatedSession = _currentSession.value.copy(
                messages = _messages.value,
                updatedAt = System.currentTimeMillis()
            )
            saveSession(updatedSession)
        }

        // å‰µå»ºæ–°æœƒè©±
        _currentSession.value = ChatSession()
        _messages.value = emptyList()
        _inputText.value = ""
        _canSendMessage.value = false
        _isAIResponding.value = false
        updateCanSendMessageState() // ç¢ºä¿ç‹€æ…‹ä¸€è‡´
        
        // åŠ è¼‰æ­¡è¿è¨Šæ¯
        loadWelcomeMessage()
        
        setSuccess(getApplicationString(R.string.new_conversation_created))
    }

    /**
     * åŠ è¼‰æœƒè©±
     */
    fun loadSession(session: ChatSession) {
        _currentSession.value = session
        _messages.value = session.messages
        _inputText.value = ""
        _canSendMessage.value = false
        _isAIResponding.value = false
        updateCanSendMessageState() // ç¢ºä¿ç‹€æ…‹ä¸€è‡´
        setSuccess(getApplicationString(R.string.conversation_loaded).format(session.title))
    }

    /**
     * æ›´æ–°æœƒè©±æ¨™é¡Œ
     */
    fun updateSessionTitle(title: String) {
        _currentSession.value = _currentSession.value.copy(
            title = title,
            updatedAt = System.currentTimeMillis()
        )
    }

    /**
     * è™•ç†è¨Šæ¯äº’å‹•
     */
    fun handleMessageInteraction(action: MessageAction, message: ChatMessage, extra: Any? = null) {
        when (action) {
            MessageAction.SPEAKER_CLICK -> {
                playTtsForMessage(message)
            }
            MessageAction.LIKE_CLICK -> {
                val isPositive = extra as? Boolean ?: true
                if (isPositive) {
                    setSuccess(getApplicationString(R.string.thank_you_positive_feedback))
                } else {
                    setSuccess(getApplicationString(R.string.will_improve_ai_quality))
                }
            }
            MessageAction.RETRY_CLICK -> {
                retryLastAIResponse()
            }
            MessageAction.LONG_CLICK -> {
                // TODO: é¡¯ç¤ºè¨Šæ¯é¸é …èœå–® (è¤‡è£½ã€åˆªé™¤ç­‰)
                setSuccess(getApplicationString(R.string.long_press_feature_in_development))
            }
            MessageAction.IMAGE_CLICK -> {
                // TODO: é¡¯ç¤ºåœ–ç‰‡å…¨è¢å¹•é è¦½
                setSuccess(getApplicationString(R.string.image_preview_feature_in_development))
            }
        }
    }

    /**
     * æ·»åŠ è¨Šæ¯åˆ°åˆ—è¡¨
     */
    private fun addMessage(message: ChatMessage) {
        val currentMessages = _messages.value.toMutableList()
        currentMessages.add(message)
        _messages.value = currentMessages
    }

    /**
     * æ›´æ–°è¨Šæ¯ç‹€æ…‹
     */
    private fun updateMessageState(messageId: String, newState: ChatMessage.MessageState) {
        val currentMessages = _messages.value.toMutableList()
        val index = currentMessages.indexOfFirst { it.id == messageId }
        if (index != -1) {
            currentMessages[index] = currentMessages[index].copy(state = newState)
            _messages.value = currentMessages
        }
    }

    /**
     * æ›´æ–°è¨Šæ¯æ–‡å­—
     */
    private fun updateMessageText(messageId: String, newText: String) {
        val currentMessages = _messages.value.toMutableList()
        val index = currentMessages.indexOfFirst { it.id == messageId }
        if (index != -1) {
            currentMessages[index] = currentMessages[index].copy(text = newText)
            _messages.value = currentMessages
        }
    }

    /**
     * Appends a chunk of text to an existing message.
     * This is the robust way to handle streaming updates.
     */
    private fun appendMessageText(messageId: String, chunk: String) {
        val currentMessages = _messages.value.toMutableList()
        val index = currentMessages.indexOfFirst { it.id == messageId }
        if (index != -1) {
            val oldMessage = currentMessages[index]
            currentMessages[index] = oldMessage.copy(text = oldMessage.text + chunk)
            _messages.value = currentMessages
        }
    }

    /**
     * æ›´æ–°ç•¶å‰æœƒè©±
     */
    private fun updateCurrentSession() {
        val updatedSession = _currentSession.value.copy(
            messages = _messages.value,
            updatedAt = System.currentTimeMillis(),
            title = generateSessionTitle()
        )
        _currentSession.value = updatedSession
        
        // ä¿å­˜åˆ°repository
        launchSafely(showLoading = false) {
            saveCurrentSessionUseCase(updatedSession)
        }
    }

    /**
     * ä¿å­˜æœƒè©±
     */
    private fun saveSession(session: ChatSession) {
        val currentSessions = _chatSessions.value.toMutableList()
        val existingIndex = currentSessions.indexOfFirst { it.id == session.id }
        
        if (existingIndex != -1) {
            currentSessions[existingIndex] = session
        } else {
            currentSessions.add(0, session) // æ–°æœƒè©±æ·»åŠ åˆ°æœ€å‰é¢
        }
        
        _chatSessions.value = currentSessions
    }

    /**
     * ç”Ÿæˆæœƒè©±æ¨™é¡Œ
     */
    private fun generateSessionTitle(): String {
        val firstUserMessage = _messages.value.firstOrNull { it.isFromUser }
        return if (firstUserMessage != null) {
            firstUserMessage.text.take(20) + if (firstUserMessage.text.length > 20) "..." else ""
        } else {
            getApplicationString(R.string.new_conversation)
        }
    }

    /**
     * è¼‰å…¥ä¹‹å‰çš„æœƒè©±æˆ–åˆå§‹åŒ–æ–°æœƒè©±
     */
    private fun loadOrInitializeSession() {
        launchSafely(showLoading = false) {
            try {
                val savedSession = loadCurrentSessionUseCase()
                if (savedSession != null) {
                    // æ¢å¾©ä¹‹å‰çš„æœƒè©±
                    _currentSession.value = savedSession
                    _messages.value = savedSession.messages
                } else {
                    // å‰µå»ºæ–°æœƒè©±ä¸¦è¼‰å…¥æ­¡è¿è¨Šæ¯
                    loadWelcomeMessage()
                }
            } catch (e: Exception) {
                // å¦‚æœè¼‰å…¥å¤±æ•—ï¼Œå‰µå»ºæ–°æœƒè©±
                loadWelcomeMessage()
            }
        }
    }

    /**
     * åŠ è¼‰æ­¡è¿è¨Šæ¯
     */
    private fun loadWelcomeMessage() {
        // åŒæ­¥åŠ è¼‰æ­¡è¿è¨Šæ¯ï¼Œé¿å…æ¸¬è©¦ä¸­çš„ç•°æ­¥å•é¡Œ
        val welcomeMessage = ChatMessage(
            text = getApplicationString(R.string.ai_welcome_message),
            isFromUser = false,
            state = ChatMessage.MessageState.NORMAL
        )
        addMessage(welcomeMessage)
        updateCurrentSession()
    }

    /**
     * ç”Ÿæˆæ¨¡æ“¬AIå›æ‡‰
     */
    private fun generateMockResponse(userInput: String): String {
        val responses = listOf(
            getApplicationString(R.string.mock_response_1),
            getApplicationString(R.string.mock_response_2),
            getApplicationString(R.string.mock_response_3),
            getApplicationString(R.string.mock_response_4),
            getApplicationString(R.string.mock_response_5),
            getApplicationString(R.string.mock_response_6),
            getApplicationString(R.string.mock_response_7),
            getApplicationString(R.string.mock_response_8)
        )
        
        return responses.random() + "\n\n" + 
               getApplicationString(R.string.mock_response_suffix)
    }

    /**
     * æ¨¡æ“¬èªéŸ³è­˜åˆ¥
     */
    private fun mockVoiceRecognition(): String {
        val phrases = listOf(
            getApplicationString(R.string.mock_voice_1),
            getApplicationString(R.string.mock_voice_2),
            getApplicationString(R.string.mock_voice_3),
            getApplicationString(R.string.mock_voice_4),
            getApplicationString(R.string.mock_voice_5)
        )
        return phrases.random()
    }

    /**
     * åˆå§‹åŒ– BreezeApp Engine é€£æ¥
     */
    private fun initializeBreezeAppEngine() {
        launchSafely(showLoading = false) {
            connectionUseCase.initialize().collect { state ->
                _connectionState.value = state
                when (state) {
                    is BreezeAppConnectionState.Connected -> {
                        setSuccess(getApplicationString(R.string.breezeapp_engine_connected))
                    }
                    is BreezeAppConnectionState.Failed -> {
                        setError(getApplicationString(R.string.breezeapp_engine_connection_failed).format(state.message))
                    }
                    else -> {
                        // è™•ç†å…¶ä»–ç‹€æ…‹
                    }
                }
            }
        }
    }
    
    /**
     * ä½¿ç”¨ BreezeApp Engine ç”ŸæˆAIå›æ‡‰
     */
    private suspend fun generateAIResponseWithBreezeApp(userInput: String) {
        var aiMessage: ChatMessage? = null
        try {
            // æª¢æŸ¥é€£æ¥ç‹€æ…‹
            if (!connectionUseCase.isConnected()) {
                throw BreezeAppError.ConnectionError.ServiceDisconnected(getApplicationString(R.string.breezeapp_engine_not_connected))
            }
            
            // å‰µå»ºAIå›æ‡‰è¨Šæ¯ (åˆå§‹ç‚ºè¼‰å…¥ç‹€æ…‹)
            aiMessage = ChatMessage(
                text = "", // Start with empty text
                isFromUser = false,
                state = ChatMessage.MessageState.TYPING
            )
            addMessage(aiMessage)
            
            // å–å¾—æœ€æ–°çš„é‹è¡Œæ™‚è¨­å®š
            val settingsResult = loadRuntimeSettingsUseCase()
            val settings = settingsResult.getOrNull()

            // å¾è¨­å®šä¸­å–å¾— LLM åƒæ•¸ï¼ˆå«é è¨­å€¼ï¼‰
            val temperature = settings?.llmParams?.temperature ?: 0.7f
            val topK = settings?.llmParams?.topK ?: 40
            val topP = settings?.llmParams?.topP ?: 0.9f
            val maxTokens = settings?.llmParams?.maxTokens ?: 2048
            val repetitionPenalty = settings?.llmParams?.repetitionPenalty ?: 1.1f
            val enableStreaming = settings?.llmParams?.enableStreaming ?: true
            val systemPrompt = settings?.llmParams?.systemPrompt?.takeIf { it.isNotBlank() }
                ?: getApplicationString(R.string.default_system_prompt)

            // DEBUG: Log runtime parameters to verify values
            Log.d(tag, "ğŸ”¥ Runtime Settings DEBUG - temperature: $temperature, topK: $topK, topP: $topP, maxTokens: $maxTokens, repetitionPenalty: $repetitionPenalty, streaming: $enableStreaming")

            if (enableStreaming) {
                // The new streaming use case is expected to handle guardian checks internally
                // and provide the final, safe content to the ViewModel.
                streamingChatUseCase.execute(
                    prompt = userInput,
                    systemPrompt = systemPrompt,
                    temperature = temperature,
                    maxTokens = maxTokens,
                    topK = topK,
                    topP = topP,
                    repetitionPenalty = repetitionPenalty
                ).collect { response ->
                    // The response from the use case contains the next chunk of text.
                    val choice = response.choices.firstOrNull()
                    
                    // Only process delta content if stream is still ongoing (no finishReason)
                    if (choice?.finishReason == null) {
                        choice?.delta?.content?.let { chunk ->
                            // Only append non-empty chunks to prevent UI flickering
                            if (chunk.isNotBlank()) {
                                appendMessageText(aiMessage.id, chunk)
                            }
                        }
                    }

                    if (choice?.finishReason != null) {
                        val finalMessage = _messages.value.find { it.id == aiMessage.id }
                        
                        // Handle non-streaming fallback: check multiple possible content locations
                        val fallbackContent = choice?.message?.content?.takeIf { it.isNotBlank() }
                            ?: choice?.delta?.content?.takeIf { it.isNotBlank() }
                         
                        when {
                            // Case 1: Normal streaming - message has accumulated content
                            finalMessage != null && finalMessage.text.isNotEmpty() -> {
                                updateMessageState(aiMessage.id, ChatMessage.MessageState.NORMAL)
                            }
                            // Case 2: Non-streaming fallback - use complete content from response  
                            fallbackContent != null -> {
                                updateMessageText(aiMessage.id, fallbackContent)
                                updateMessageState(aiMessage.id, ChatMessage.MessageState.NORMAL)
                            }
                            // Case 3: Truly empty response
                            else -> {
                                val errorMessage = getApplicationString(R.string.ai_response_empty_retry_check_settings)
                                updateMessageText(aiMessage.id, errorMessage)
                                updateMessageState(aiMessage.id, ChatMessage.MessageState.ERROR)
                            }
                        }
                    }
                }
            } else {
                // éä¸²æµæ¨¡å¼
                val response = chatUseCase.execute(
                    prompt = userInput,
                    systemPrompt = systemPrompt,
                    temperature = temperature,
                    maxTokens = maxTokens,
                    topK = topK,
                    topP = topP,
                    repetitionPenalty = repetitionPenalty
                )
                
                // Robust content extraction - try multiple possible response formats
                val content = response.choices.firstOrNull()?.let { choice ->
                    choice.message?.content                      // Standard format
                        ?: choice.delta?.content                 // Streaming format fallback
                        ?: ""
                } ?: ""
                
                if (content.isNotEmpty()) {
                    updateMessageText(aiMessage.id, content)
                } else {
                    // Handle truly empty response - check if it's Guardian blocking
                    Log.w(tag, "ğŸ›¡ï¸ Empty non-streaming response - checking for Guardian or other issues")
                    val errorMessage = getApplicationString(R.string.ai_response_generation_error_retry)
                    updateMessageText(aiMessage.id, errorMessage)
                    updateMessageState(aiMessage.id, ChatMessage.MessageState.ERROR)
                }
            }
            
            // æ›´æ–°è¨Šæ¯ç‹€æ…‹ç‚ºæ­£å¸¸ (åªæœ‰åœ¨ééŒ¯èª¤æƒ…æ³ä¸‹)
            if (_messages.value.find { it.id == aiMessage.id }?.state != ChatMessage.MessageState.ERROR) {
                updateMessageState(aiMessage.id, ChatMessage.MessageState.NORMAL)
            }
            
            // æ›´æ–°æœƒè©±
            updateCurrentSession()
            
            setSuccess(getApplicationString(R.string.ai_response_completed))
            
        } catch (e: BreezeAppError) {
            aiMessage?.let { message ->
                handleBreezeAppError(e, message)
            } ?: run {
                Log.e(tag, "âŒ aiMessage is null, cannot update with error message")
            }
        } catch (e: Exception) {
            handleAIResponseError(e)
        }
    }
    
    /**
     * è™•ç† BreezeApp Engine éŒ¯èª¤
     */
    private suspend fun handleBreezeAppError(error: BreezeAppError, aiMessage: ChatMessage) {
        val errorMessage = when (error) {
            is BreezeAppError.ConnectionError.ServiceDisconnected -> getApplicationString(R.string.breezeapp_engine_connection_interrupted)
            is BreezeAppError.ChatError.InvalidInput -> getApplicationString(R.string.input_format_incorrect)
            is BreezeAppError.ChatError.ModelNotFound -> getApplicationString(R.string.ai_model_not_found)
            is BreezeAppError.ChatError.GenerationFailed -> getApplicationString(R.string.ai_response_generation_failed)
            is BreezeAppError.ChatError.StreamingError -> {
                // Preserve the actual error message (may contain Guardian violation messages)
                error.message?.takeIf { it.isNotBlank() } ?: getApplicationString(R.string.streaming_response_interrupted)
            }
            // TTS-specific errors - preserve actual error message for better diagnostics
            is BreezeAppError.TtsError.AudioGenerationFailed -> {
                getApplicationString(R.string.tts_generation_failed).format(error.message)
            }
            is BreezeAppError.TtsError.InvalidText -> getApplicationString(R.string.tts_invalid_text)
            is BreezeAppError.TtsError.UnsupportedLanguage -> getApplicationString(R.string.tts_unsupported_language)
            is BreezeAppError.TtsError.AudioFocusLost -> getApplicationString(R.string.tts_audio_focus_lost)
            is BreezeAppError.TtsError.AppBackgrounded -> getApplicationString(R.string.tts_app_backgrounded)
            // ASR-specific errors
            is BreezeAppError.AsrError.ResourceUnavailable -> {
                getApplicationString(R.string.asr_resource_unavailable).format(error.message)
            }
            // For any other errors, show the actual error message if available
            else -> error.message?.takeIf { it.isNotBlank() } ?: getApplicationString(R.string.unknown_error_retry)
        }
        
        updateMessageText(aiMessage.id, errorMessage)
        updateMessageState(aiMessage.id, ChatMessage.MessageState.ERROR)
        setError(errorMessage)
    }
    
    

    private fun playTtsForMessage(message: ChatMessage) {
        // Simple approach: Only allow ONE TTS at a time
        // If TTS is already playing, show friendly message to user
        if (_currentlyPlayingMessageId.value != null) {
            Log.d(TAG, "TTS already playing for message ${_currentlyPlayingMessageId.value}, ignoring request")
            setSuccess(getApplicationString(R.string.tts_already_playing_please_wait))
            return
        }

        // Cancel any existing TTS job (safety check)
        currentTtsJob?.cancel()

        // Mark this message as currently playing
        _currentlyPlayingMessageId.value = message.id

        currentTtsJob = viewModelScope.launch {
            try {
                if (!connectionUseCase.isConnected()) {
                    throw BreezeAppError.ConnectionError.ServiceDisconnected(getApplicationString(R.string.breezeapp_engine_not_connected))
                }

                // å¾ç•¶å‰ç‹€æ…‹ç²å–æœ€æ–°çš„è¨Šæ¯å…§å®¹ï¼Œé¿å…ä½¿ç”¨éæœŸçš„è¨Šæ¯å¼•ç”¨
                val currentMessage = _messages.value.find { it.id == message.id }
                val textToSpeak = currentMessage?.text ?: message.text

                if (textToSpeak.isEmpty() || textToSpeak == getApplicationString(R.string.ai_thinking_message)) {
                    setError(getApplicationString(R.string.cannot_play_empty_or_loading_message))
                    return@launch
                }

                ttsUseCase.execute(textToSpeak).collect { response ->
                    // TTS streaming response received, audio is being played
                    Log.d(TAG, "TTS response received: ${response.audioData.size} bytes")
                }
                // TTS stream completed
                setSuccess(getApplicationString(R.string.voice_playback_completed))
            } catch (e: kotlinx.coroutines.CancellationException) {
                Log.d(TAG, "TTS playback cancelled")
                throw e
            } catch (e: BreezeAppError) {
                // ä½¿ç”¨ç•¶å‰è¨Šæ¯é€²è¡ŒéŒ¯èª¤è™•ç†
                val currentMessage = _messages.value.find { it.id == message.id } ?: message
                handleBreezeAppError(e, currentMessage)
            } catch (e: Exception) {
                handleAIResponseError(e)
            } finally {
                // Always clear the playing state when done
                if (_currentlyPlayingMessageId.value == message.id) {
                    _currentlyPlayingMessageId.value = null
                }
                currentTtsJob = null
            }
        }
    }

    /**
     * Stop current TTS playback
     */
    fun stopCurrentTts() {
        currentTtsJob?.cancel()
        currentTtsJob = null
        _currentlyPlayingMessageId.value = null
        Log.d(TAG, "ğŸ›‘ TTS playback stopped")
    }
    
    /**
     * é‡é€£ BreezeApp Engine
     */
    fun reconnectBreezeAppEngine() {
        launchSafely(showLoading = false) {
            connectionUseCase.connect().collect { state ->
                _connectionState.value = state
                when (state) {
                    is BreezeAppConnectionState.Connected -> {
                        setSuccess(getApplicationString(R.string.breezeapp_engine_reconnected))
                    }
                    is BreezeAppConnectionState.Failed -> {
                        setError(getApplicationString(R.string.breezeapp_engine_reconnection_failed).format(state.message))
                    }
                    else -> {
                        // è™•ç†å…¶ä»–ç‹€æ…‹
                    }
                }
            }
        }
    }
    
    /**
     * å–æ¶ˆç•¶å‰ä¸²æµè«‹æ±‚
     */
    fun cancelCurrentStreamingRequest() {
        currentStreamingRequestId?.let { requestId ->
            // Launch coroutine for suspend function
            viewModelScope.launch {
                try {
                    requestCancellationUseCase.cancelRequest(requestId)
                    currentStreamingRequestId = null
                } catch (e: Exception) {
                    Log.w(TAG, "Failed to cancel streaming request: ${e.message}")
                }
            }
        }
    }

    /**
     * ç•¶ViewModelè¢«æ¸…é™¤æ™‚èª¿ç”¨
     * é€™é€šå¸¸ç™¼ç”Ÿåœ¨Activity/Fragmentè¢«æ°¸ä¹…éŠ·æ¯€æ™‚
     */
    override fun onCleared() {
        super.onCleared()
        
        // ä¿å­˜ç•¶å‰æœƒè©±ç‹€æ…‹ï¼Œä»¥ä¾¿ä¸‹æ¬¡å•Ÿå‹•æ™‚æ¢å¾©
        if (_messages.value.isNotEmpty()) {
            val currentSession = _currentSession.value.copy(
                messages = _messages.value,
                updatedAt = System.currentTimeMillis(),
                title = generateSessionTitle()
            )
            // ä½¿ç”¨ä¸€å€‹ç¨ç«‹çš„scopeä¾†ä¿å­˜ï¼Œå› ç‚ºviewModelScopeå¯èƒ½å·²ç¶“è¢«å–æ¶ˆ
            viewModelScope.launch {
                try {
                    saveCurrentSessionUseCase(currentSession)
                } catch (e: Exception) {
                    // å¿½ç•¥ä¿å­˜éŒ¯èª¤ï¼Œé¿å…å´©æ½°
                }
            }
        }
    }

    /**
     * è¨Šæ¯äº’å‹•å‹•ä½œæšèˆ‰
     */
    enum class MessageAction {
        SPEAKER_CLICK,  // èªéŸ³æ’­æ”¾
        LIKE_CLICK,     // é»è®š/é»è¸©
        RETRY_CLICK,    // é‡è©¦
        LONG_CLICK,     // é•·æŒ‰
        IMAGE_CLICK     // åœ–ç‰‡é»æ“Š
    }
} 

// æä¾›æ¸¬è©¦èˆ‡é è¨­æƒ…å¢ƒå¯ç”¨çš„ç°¡æ˜“å…§å­˜èŠå¤©å„²å­˜åº«
private object DefaultChatRepository : ChatRepository {
    private var currentSession: ChatSession? = null
    private val sessionFlow = kotlinx.coroutines.flow.MutableStateFlow<ChatSession?>(null)

    override suspend fun getCurrentSession(): ChatSession? = currentSession

    override suspend fun saveCurrentSession(session: ChatSession) {
        currentSession = session
        sessionFlow.value = session
    }

    override suspend fun clearCurrentSession() {
        currentSession = null
        sessionFlow.value = null
    }

    override fun observeCurrentSession(): kotlinx.coroutines.flow.Flow<ChatSession?> = sessionFlow
}